\changetocdepth {3}
\babel@toc {english}{}\relax 
\contentsline {chapter}{TABLE OF CONTENTS}{i}{section*.1}%
\contentsline {chapter}{LIST OF TABLES}{v}{section*.2}%
\contentsline {chapter}{LIST OF FIGURES}{vi}{section*.3}%
\vspace {1.7cm}
\contentsline {chapter}{\chapternumberline {1}INTRODUCTION}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Research Background}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Problem Statement}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Research Objectives}{3}{section.1.3}%
\contentsline {section}{\numberline {1.4}Research Questions}{3}{section.1.4}%
\contentsline {section}{\numberline {1.5}Scope of Study}{3}{section.1.5}%
\contentsline {section}{\numberline {1.6}Significance of Study}{4}{section.1.6}%
\contentsline {section}{\numberline {1.7}Conclusion}{5}{section.1.7}%
\contentsline {chapter}{\chapternumberline {2}LITERATURE REVIEW}{6}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{6}{section.2.1}%
\contentsline {section}{\numberline {2.2}Challenges in Japanese Speech Detection}{7}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Complexity of Japanese Writing System and Characters}{7}{subsection.2.2.1}%
\contentsline {section}{\numberline {2.3}Traditional Speech Detection Models }{7}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Gaussian Mixture Models (GMM)}{7}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Hidden Markov Models (HMM)}{8}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}The GMM-HMM Combination}{9}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Modern Deep Learning Approaches}{10}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Deep Neural Networks (DNN)}{10}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Convolutional Neural Networks (CNN)}{11}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Recurrent Neural Networks (RNN)}{11}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Convolutional-Recurrent DNN with Connectionist Temporal Classification (CRDNN-CTC)}{12}{subsection.2.4.4}%
\contentsline {section}{\numberline {2.5}Transformers Models in Japanese Speech Recognition}{13}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Transformer-based Models}{13}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Whisper by OpenAI}{14}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}wav2vec 2.0 by Facebook AI Research}{15}{subsection.2.5.3}%
\contentsline {subsection}{\numberline {2.5.4}ChirpV2: an Universal speech model from Google}{17}{subsection.2.5.4}%
\contentsline {section}{\numberline {2.6}Current Comparative Analysis of Japanese ASR Models}{17}{section.2.6}%
\contentsline {section}{\numberline {2.7} Datasets and Tools }{19}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Datasets}{19}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Python}{20}{subsection.2.7.2}%
\contentsline {subsection}{\numberline {2.7.3}yt-dlp}{20}{subsection.2.7.3}%
\contentsline {subsection}{\numberline {2.7.4}Kaldi}{20}{subsection.2.7.4}%
\contentsline {subsection}{\numberline {2.7.5}speechbrain}{20}{subsection.2.7.5}%
\contentsline {subsection}{\numberline {2.7.6}Hugging Face}{21}{subsection.2.7.6}%
\contentsline {section}{\numberline {2.8}Gaps in Literature}{21}{section.2.8}%
\contentsline {section}{\numberline {2.9}Conclusion}{21}{section.2.9}%
\contentsline {chapter}{\chapternumberline {3}RESEARCH METHODOLOGY}{23}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{23}{section.3.1}%
\contentsline {section}{\numberline {3.2}Research Design}{23}{section.3.2}%
\contentsline {section}{\numberline {3.3}Data Collection Pipeline}{24}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Data Source Selection}{25}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Data Scraping in Python}{25}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Transcript Cleaning and Normalization}{26}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Audio Segmentation}{26}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5}Resampling and Format Standardization}{27}{subsection.3.3.5}%
\contentsline {subsection}{\numberline {3.3.6}Train / Validation / Test Split}{28}{subsection.3.3.6}%
\contentsline {section}{\numberline {3.4}Text Preparation for ASR Training}{28}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Lexicon and Token Units}{29}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Buildiing Language Model Text for the GMM--HMM}{29}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Feature Extraction and Front-End Processing}{30}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}MFCC with Cepstral Mean and Variance Normalization}{30}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Log-Mel Filterbank and Spectrogram-Derived Features}{31}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Data Augmentation}{32}{subsection.3.5.3}%
\contentsline {section}{\numberline {3.6}Model Family A: GMM--HMM Acoustic Model}{33}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Data and Language Preparation}{33}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Acoustic Features}{35}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Training Schedule}{36}{subsection.3.6.3}%
\contentsline {subsection}{\numberline {3.6.4}Decoding Graph Construction}{36}{subsection.3.6.4}%
\contentsline {subsection}{\numberline {3.6.5}Inference and Lattice Rescoring}{37}{subsection.3.6.5}%
\contentsline {subsection}{\numberline {3.6.6}Scoring}{37}{subsection.3.6.6}%
\contentsline {section}{\numberline {3.7}Model Family B: CRDNN–CTC (End-to-End, Non-Transformer)}{38}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}Data and Supervision}{38}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}Acoustic Features and Augmentation}{38}{subsection.3.7.2}%
\contentsline {subsection}{\numberline {3.7.3}Training Procedure}{39}{subsection.3.7.3}%
\contentsline {subsection}{\numberline {3.7.4}Decoding}{39}{subsection.3.7.4}%
\contentsline {subsection}{\numberline {3.7.5}Post-Processing and Normalization}{39}{subsection.3.7.5}%
\contentsline {subsection}{\numberline {3.7.6}Scoring}{39}{subsection.3.7.6}%
\contentsline {section}{\numberline {3.8}Model Family C: Whisper (Transformer Encoder–Decoder, Fine-Tuned)}{40}{section.3.8}%
\contentsline {subsection}{\numberline {3.8.1}Model Overview}{40}{subsection.3.8.1}%
\contentsline {subsection}{\numberline {3.8.2}Dataset Formatting and Inputs}{40}{subsection.3.8.2}%
\contentsline {subsection}{\numberline {3.8.3}Fine-Tuning Configuration}{40}{subsection.3.8.3}%
\contentsline {subsection}{\numberline {3.8.4}Inference and Decoding}{41}{subsection.3.8.4}%
\contentsline {subsection}{\numberline {3.8.5}Normalization and Style Consistency}{41}{subsection.3.8.5}%
\contentsline {subsection}{\numberline {3.8.6}Scoring}{41}{subsection.3.8.6}%
\contentsline {section}{\numberline {3.9}Unified Evaluation Protocol}{41}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}Accuracy: CER and WER}{41}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}Latency: Real-Time Factor}{42}{subsection.3.9.2}%
\contentsline {subsection}{\numberline {3.9.3}Consistency and Comparability}{42}{subsection.3.9.3}%
\contentsline {section}{\numberline {3.10}Challenges and Limitations}{42}{section.3.10}%
\contentsline {section}{\numberline {3.11}Ethical Considerations}{43}{section.3.11}%
\contentsline {section}{\numberline {3.12}Chapter Summary}{43}{section.3.12}%
\contentsline {chapter}{REFERENCES}{45}{section*.15}%
